mythril:
  # Path to where benchbase.jar can be found.
  benchbase_path: /home/wz2/noisepage-pilot/artifacts/benchbase
  benchbase_config_path: "/home/wz2/noisepage-pilot/config/behavior/benchbase/tpch_config.xml"
  # Directory where we can find postgres, psql, and pgdata.
  postgres_path: /mnt/nvme0n1/wz2/noisepage
  postgres_data: pgdata
  postgres_port: 5432
  postgres_host: localhost
  postgres_db: benchbase
  postgres_user: admin
  postgres_password: password

  # Path to a snapshot of the data archive.
  data_snapshot_path: "data/tpch_sf10.tgz"

  # Path to emit log file.
  output_log_path: artifacts/
  # Directory where to write tensorboard output.
  tensorboard_path: artifacts/runs/
  # Directory where to store repository of training data.
  repository_path: artifacts/repository/
  dump_path: artifacts/dump.pickle

  workload_eval_mode: "all" # Either "global_dual", "prev_dual" or "all"
  workload_eval_inverse: True

  # verbose
  verbose: True
  no_trace: False

  # Connection timeout.
  connect_timeout: 30

  # Whether to quantize the knobs.
  enable_quantize: True
  # Default quantization factor to use.
  default_quantization_factor: 10

  # Can be "metric", "structure"
  metric_state: "metric"

  scale_noise_perturb: False

  knob_space: True
  index_space: True

  index_vae_metadata:
    index_vae: False
    embeddings: "vae_models/model13/embedder_15.pth"

  lsc_parameters:
    lsc_enabled: False
    lsc_embed: True

    # Note that the units for these are based on the embedding itself.
    # These are the initial low-bias, comma separated by the horizon step.
    lsc_shift_initial: "0"
    # These are the units for how much to increment the low-bias by each time.
    lsc_shift_increment: "0"
    # Maximum allowed shift.
    lsc_shift_max: "0"
    # This controls how frequently to try and boost the shifts based on episode.
    lsc_shift_schedule_eps_freq: 1
    # How many episodes to start.
    lsc_shift_after: 3

  # Representation of an index [ONE_HOT, ONE_HOT_DETERMINISTIC]
  index_repr: "ONE_HOT"

  # Reward scaler.
  reward_scaler: 1

  # Whether to normalize the state.
  normalize_state: True
  # Whether to normalize the reward.
  normalize_reward: False
  # Whether we should maximize the state.
  maximize_state: True
  # Discount factor for rewards.
  gamma: 0.99
  # Gradient Clipping.
  grad_clip: 0

  # TODO: Can we use a version of curriculum learning to more quickly stabilize?
  # What is the right granularity for doing that? Knobs/Indexes/expand??

  system_knobs:
    # Knob Specification
    # <knob_name>:
    #   type: <boolean, integer, bytes, integer_time, float>
    #   min: <min_value>
    #   max: <max_value>
    #   quantize: <number of elements to quantize by, -1 for default_quantization_factor>
    #   log_scale: <1 if using log2 scale, 0 otherwise>
    #   unit: <unit to divide by to the base unit>

    # Starts the autovacuum subprocess
    autovacuum:                             {type: "boolean", min: 0, max: 1, quantize: 0, log_scale: 0, unit: 0}
    # Minimum number of tuple inserts, updates, or deletes prior to analyze.
    autovacuum_analyze_threshold:           {type: "integer", min: 0, max: 2147483647, quantize: 0, log_scale: 1, unit: 0}
    # Number of tuple inserts, updates, or deletes prior to analyze as a fraction of reltuples.
    autovacuum_analyze_scale_factor:        {type: "float", min: 0, max: 1, quantize: 10, log_scale: 0, unit: 0}
    # Sets the maximum number of simultaneously running autovacuum worker processes
    autovacuum_max_workers:                 {type: "integer", min: 1, max: 20, quantize: 0, log_scale: 0, unit: 0}
    # Time to sleep between autovacuum runs (sec unit).
    autovacuum_naptime:                     {type: "integer_time", min: 60, max: 300, quantize: 8, log_scale: 0, unit: 1000000}
    # Vacuum cost delay in milliseconds, for autovacuum (ms unit).
    autovacuum_vacuum_cost_delay:           {type: "integer_time", min: 0, max: 100, quantize: -1, log_scale: 0, unit: 1000}
    # Vacuum cost amount available before napping, for autovacuum.
    autovacuum_vacuum_cost_limit:           {type: "integer", min: 1, max: 10000, quantize: -1, log_scale: 0, unit: 0}
    # Minimum number of tuple updates or deletes prior to vacuum.
    autovacuum_vacuum_threshold:            {type: "integer", min: 0, max: 2147483647, quantize: 0, log_scale: 1, unit: 0}
    # Minimum number of tuple inserts prior to vacuum, or -1 to disable insert vacuums.
    autovacuum_vacuum_insert_threshold:     {type: "integer", min: -1, max: 2147483647, quantize: 0, log_scale: 1, unit: 0}
    # Number of tuple updates or deletes prior to vacuum as a fraction of reltuples.
    autovacuum_vacuum_scale_factor:         {type: "float", min: 0, max: 100, quantize: -1, log_scale: 0, unit: 0}
    # Number of tuple inserts prior to vacuum as a fraction of reltuples.
    autovacuum_vacuum_insert_scale_factor:  {type: "float", min: 0, max: 100, quantize: -1, log_scale: 0, unit: 0}
    # Sets the maximum memory to be used by each autovacuum worker process (1kB unit) -- 4GB.
    autovacuum_work_mem:                    {type: "bytes", min: 1024, max: 4194304, quantize: 0, log_scale: 1, unit: 1024}

    # Number of pages after which previously performed writes are flushed to disk (8kb unit).
    backend_flush_after:                    {type: "bytes", min: 0, max: 256, quantize: -1, log_scale: 0, unit: 8192}
    # Background writer sleep time between rounds (ms unit).
    bgwriter_delay:                         {type: "integer_time", min: 10, max: 10000, quantize: -1, log_scale: 0, unit: 1000}
    # Number of pages after which previously performed writes are flushed to disk (page unit).
    bgwriter_flush_after:                   {type: "bytes", min: 0, max: 256, quantize: -1, log_scale: 0, unit: 8192}
    # Background writer maximum number of LRU pages to flush per round  (page unit) -- see shared_buffers.
    bgwriter_lru_maxpages:                  {type: "integer", min: 0, max: 4194304, quantize: 0, log_scale: 1, unit: 0}
    # Multiple of the average buffer usage to free per round (float multiplier).
    bgwriter_lru_multiplier:                {type: "float", min: 2, max: 10, quantize: -1, log_scale: 0, unit: 0}
    # Time spent flushing dirty buffers during checkpoint, as fraction of checkpoint interval (float).
    checkpoint_completion_target:           {type: "float", min: 0, max: 1, quantize: 10, log_scale: 0, unit: 0}
    # Sets the maximum time between automatic WAL checkpoints (sec unit).
    checkpoint_timeout:                     {type: "integer_time", min: 30, max: 300, quantize: 9, log_scale: 0, unit: 1000000}
    # Number of pages after which previously performed writes are flushed to disk (page unit).
    checkpoint_flush_after:                 {type: "bytes", min: 0, max: 256, quantize: -1, log_scale: 0, unit: 8192}

    # Sets the delay in microseconds between transaction commit and flushing WAL to disk (us unit).
    commit_delay:                           {type: "integer_time", min: 0, max: 100000, quantize: 10, log_scale: 0, unit: 0}
    # Sets the minimum number of concurrent open transactions required before performing commit_delay.
    commit_siblings:                        {type: "integer", min: 0, max: 20, quantize: -1, log_scale: 0, unit: 0}
    # Sets the time to wait on a lock before checking for deadlock (ms unit) -- 1 second.
    deadlock_timeout:                       {type: "integer_time", min: 1, max: 1000000, quantize: 1000, log_scale: 0, unit: 1000}

    # Allow JIT compilation.
    jit:                                    {type: "boolean", min: 0, max: 1, quantize: 0, log_scale: 0, unit: 0}
    # Allow JIT compilation of expressions.
    jit_expressions:                        {type: "boolean", min: 0, max: 1, quantize: 0, log_scale: 0, unit: 0}
    # Perform JIT compilation if query is more expensive.
    jit_above_cost:                         {type: "float", min: 0, max: 1.0E+8, quantize: 0, log_scale: 1, unit: 0}
    # Perform JIT inlining if query is more expensive.
    jit_inline_above_cost:                  {type: "float", min: -1, max: 1.0E+8, quantize: 0, log_scale: 1, unit: 0}
    # Optimize JIT-compiled functions if query is more expensive.
    jit_optimize_above_cost:                {type: "float", min: -1, max: 1.0E+8, quantize: 0, log_scale: 1, unit: 0}
    # Allow JIT compilation of tuple deforming.
    jit_tuple_deforming:                    {type: "boolean", min: 0, max: 1, quantize: 0, log_scale: 0, unit: 0}

    # Sets the planner's assumption about the total size of the data caches (8kb unit) -- 32GB.
    effective_cache_size:                   {type: "bytes", min: 1, max: 4194304, quantize: 0, log_scale: 1, unit: 8192}
    # Number of simultaneous requests that can be handled efficiently by the disk subsystem.
    effective_io_concurrency:               {type: "integer", min: 0, max: 1000, quantize: -1, log_scale: 0, unit: 0}
    # A variant of effective_io_concurrency that is used for maintenance work.
    maintenance_io_concurrency:             {type: "integer", min: 0, max: 1000, quantize: -1, log_scale: 0, unit: 0}

    ## Enables the planner's use of explicit sort steps.
    #enable_sort:                            {type: "boolean", min: 0, max: 1, quantize: 0, log_scale: 0, unit: 0}
    ## Enables or disables the query planner's use of gather merge plan types.
    #enable_gathermerge:                     {type: "boolean", min: 0, max: 1, quantize: 0, log_scale: 0, unit: 0}
    ## Enables or disables the query planner's use of hash-agg plan types.
    #enable_hashagg:                         {type: "boolean", min: 0, max: 1, quantize: 0, log_scale: 0, unit: 0}
    ## Enables or disables the query planner's use of hash-join plan types with parallel hash.
    #enable_parallel_hash:                   {type: "boolean", min: 0, max: 1, quantize: 0, log_scale: 0, unit: 0}
    ## Enables or disables the query planner's use of materialization.
    #enable_material:                        {type: "boolean", min: 0, max: 1, quantize: 0, log_scale: 0, unit: 0}
    ## Enables or disables the query planner's use of memoize plans.
    #enable_memoize:                         {type: "boolean", min: 0, max: 1, quantize: 0, log_scale: 0, unit: 0}
    ## Sets the planner's estimate of the cost of a nonsequentially fetched disk page.
    #random_page_cost:                       {type: "float", min: 0, max: 2048, quantize: 0, log_scale: 1, unit: 0}
    ## Sets the planner's estimate of the cost of a sequentially fetched disk page.
    #seq_page_cost:                          {type: "float", min: 0, max: 2048, quantize: 0, log_scale: 1, unit: 0}

    # Sets the maximum number of background processes that the system can support.
    max_worker_processes:                   {type: "integer", min: 0, max: 20, quantize: -1, log_scale: 0, unit: 0}
    # Sets the maximum number of workers that the system can support for parallel operations.
    max_parallel_workers:                   {type: "integer", min: 0, max: 20, quantize: -1, log_scale: 0, unit: 0}
    # Sets the maximum number of workers that can be started by a single Gather or Gather Merge node.
    max_parallel_workers_per_gather:        {type: "integer", min: 0, max: 20, quantize: -1, log_scale: 0, unit: 0}
    # Sets the maximum number of parallel workers that can be started by a single utility command.
    max_parallel_maintenance_workers:       {type: "integer", min: 0, max: 20, quantize: -1, log_scale: 0, unit: 0}

    # Sets the number of disk-page buffers in shared memory for WAL (8kB unit) -- 128MB.
    wal_buffers:                            {type: "bytes", min: 8, max: 16384, quantize: 0, log_scale: 1, unit: 8192}
    # Compresses full-page writes written in WAL file with specified method.
    wal_compression:                        {type: "binary_enum", min: 0, max: 1, quantize: 0, log_scale: 0, unit: 0}
    # Time between WAL flushes performed in the WAL writer (ms).
    wal_writer_delay:                       {type: "integer_time", min: 1, max: 1000, quantize: 0, log_scale: 1, unit: 1000}
    # Amount of WAL written out by WAL writer that triggers a flush (8kB unit).
    wal_writer_flush_after:                 {type: "bytes", min: 0, max: 2097152, quantize: 0, log_scale: 1, unit: 8192}
    # Sets the WAL size that triggers a checkpoint (1MB unit).
    max_wal_size:                           {type: "bytes", min: 32, max: 16384, quantize: 16, log_scale: 0, unit: 1048576}
    # Sets the minimum size to shrink the WAL to.
    min_wal_size:                           {type: "bytes", min: 32, max: 16384, quantize: 16, log_scale: 0, unit: 1048576}

    # Multiple of work_mem to use for hash tables.
    #hash_mem_multiplier:                    {type: "float", min: 1, max: 1000, quantize: 1000, log_scale: 0, unit: 0}
    # Sets the maximum memory to be used for maintenance operations (1kB unit) -- 4GB.
    maintenance_work_mem:                   {type: "bytes", min: 1024, max: 4194304, quantize: 0, log_scale: 1, unit: 1024}
    # Sets the number of shared memory buffers used by the server (8kb unit, 128KB - 32GB).
    shared_buffers:                         {type: "bytes", min: 256, max: 4194304, quantize: 0, log_scale: 1, unit: 8192}
    # Sets the maximum memory to be used for query workspaces (1kB unit).
    work_mem:                               {type: "bytes", min: 64, max: 4194304, quantize: 0, log_scale: 1, unit: 1024}
